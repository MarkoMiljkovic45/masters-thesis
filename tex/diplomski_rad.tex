\documentclass[diplomskirad, upload]{fer}
% Dodaj opciju upload za generiranje konačne verzije koja se učitava na FERWeb
% Add the option upload to generate the final version which is uploaded to FERWeb


% Ovdje dodati pakete npr. \usepackage{blindtext}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{graphicx}


%--- PODACI O RADU / THESIS INFORMATION ----------------------------------------

% Naslov na engleskom jeziku / Title in English
\title{TBD}

% Naslov na hrvatskom jeziku / Title in Croatian
\naslov{TBD}

% Broj rada / Thesis number
\brojrada{1234}

% Autor / Author
\author{Marko Miljković}

% Mentor 
\mentor{doc.~dr.~sc.~Stjepan~Begušić}

% Datum rada na engleskom jeziku / Date in English
\date{February, 2026}

% Datum rada na hrvatskom jeziku / Date in Croatian
\datum{Veljača, 2026.}

%-------------------------------------------------------------------------------


\begin{document}


% Naslovnica se automatski generira / Titlepage is automatically generated
\maketitle


%--- ZADATAK / THESIS ASSIGNMENT -----------------------------------------------

% Zadatak se ubacuje iz vanjske datoteke / Thesis assignment is included from external file
% Upiši ime PDF datoteke preuzete s FERWeb-a / Enter the filename of the PDF downloaded from FERWeb
\zadatak{zadatak.pdf}


%--- ZAHVALE / ACKNOWLEDGMENT --------------------------------------------------

\begin{zahvale}
  % Ovdje upišite zahvale / Write in the acknowledgment
  TODO Zahvala
\end{zahvale}


% Odovud započinje numeriranje stranica / Page numbering starts from here
\mainmatter


% Sadržaj se automatski generira / Table of contents is automatically generated
\tableofcontents


%--- UVOD / INTRODUCTION -------------------------------------------------------
\chapter{Uvod}
\label{pog:uvod}

TODO Uvod.

%-------------------------------------------------------------------------------
\chapter{Metodologija}
\label{pog:metodologija}

Ovo poglavlje pokriva teoretsku osnovu potrebnu za razumijevanje implementiranog modela dubokog učenja te 
strukturu podataka na kojima se primjenjuje. Prvo ćemo definirati osnovne varijable koje ćeemo se oslanjati
u ovom radu. Zatim ćemo proučiti njihova statistička svojstva. Nakon toga razmotrit ćemo faktorske modele
koji omogućuju modeliranje naših varijabli. Na kraju ćemo pokriti duboko učenje i specifičnu arhitekturu
koja će se koristiti u ovom radu.

\section{Povrati imovine}
\label{sec:povrati}

Vrijednosni papiri predstavljaju financijske instrumente koji potvrđuju određena imovinska ili
druga prava njihova vlasnika, poput prava na udio u vlasništvu poduzeća (dionice) ili prava na
povrat uloženih sredstava uz kamatu (obveznice). Njima se trguje na organiziranim tržištima kapitala,
poput burzi, gdje se kupnja i prodaja odvijaju putem ovlaštenih posrednika, a cijene se formiraju na
temelju ponude i potražnje. Tržišna cijena vrijednosnog papira u svakom trenutku odražava ravnotežu
između kupaca i prodavatelja, pri čemu se svaka realizirana transakcija bilježi kao nova referentna cijena.
Tržišni indeksi predstavljaju promjene vrijednosti grupe dionica ili drugih financijskih
instrumenata. Služe kao mjerilo performansi tržišta ili određenog segmenta tržišta \cite{anafin02}.

Kako bi se omogućila analiza kretanja cijena kroz vrijeme, kontinuirani tok transakcijskih podataka
uzorkuje se u diskretnim vremenskim intervalima (npr. minute, sati, dani), čime se dobivaju vremenski
nizovi cijena koji služe kao temelj za statističku analizu i modeliranje. Slika \ref{fig:spy-price}
prikazuje kretanje dnevnih cijena za SPDR S\&P 500 ETF \engl{ exchange traded fund} od njegovog
začeća 1993. do kraja 2025. godine.

\begin{figure}[htb]
\centering
\includegraphics[width=\textwidth]{img/spy_price_plot.pdf}
\caption{Kretanje cijene SPDR S\&P 500 ETF-a}
\label{fig:spy-price}
\end{figure}

U ovom radu koristit ćemo povrate umijesto samih cijena imovina. Postoje dva glavna razloga za to.
Prvi je to što povrati sažimaju kretanja cijena te ih stavljaju na jednaku i usporedivu skalu.
Drugi se odnosi na povoljnija statistička svojstva povrata u odnosu na cijene. Postoji više načina za
definirati povrate \cite{campbell1997}.


\subsubsection{Jednostavni (artimetički) povrati}
\label{subsubsec:artimeticki}

Nek je $P_t$ cijena imovine u trenutku $t$. Ako imovinu posjedujemo od trenutka $t-1$ do trenutka $t$,
ostvareni artimetički povrat dobivamo izrazom:
\begin{align}
  1 + R_t &= \frac{P_t}{P_{t-1}} \label{eq:artimeticki_gross} \\[12pt]
  R_t &= \frac{P_t}{P_{t-1}} - 1 = \frac{P_t - P_{t-1}}{P_{t-1}} \label{eq:artimeticki}
\end{align}

Ukoliko imovinu držimo kroz $T$ perioda ukupni artimetički povrat dobivamo ukamaćivanjem artimetičkih
povrata u vremenu \cite{tsay2010}:
\begin{equation} \label{eq:artimeticki-ukamacivanje}
\begin{split}
  1 + R_{total} = \frac{P_T}{P_1} &= \frac{P_T}{P_{T-1}} \times \frac{P_{T-1}}{P_{T-2}} \times ... \times \frac{P_2}{P_1} \\
  &= (1+R_T)(1+R_{T-1})\ ...\ (1+R_1) \\
  &= \prod_{t=1}^{T}(1 + R_t).
\end{split}
\end{equation}


\subsubsection{Kontinuirani (logaritamski) povrati}
\label{subsubsec:logaritamski}

Prirodni logaritam artimetičkog povrata (\ref{eq:artimeticki_gross}) je logaritamski povrat:
\begin{equation}
  r_t = \ln(1 + R_t) = \ln\frac{P_t}{P_{t-1}} = p_t - p_{t-1},
\label{eq:logartiamski}
\end{equation}
gdje $p_t = \ln(P_t)$.

Razmotrimo zatim ukamaćivanje logaritamskih povrata u vremenu:
\begin{equation} \label{eq:logaritamski-ukamacivanje}
\begin{split}
  r_{total} &= \ln(1 + R_{total}) = \ln[(1+R_T)(1+R_{T-1})\ ...\ (1+R_1)] \\
  &= \ln(1+R_T) + \ln(1+R_{T-1}) +\ ...\ + \ln(1+R_1) \\
  &= r_T + r_{T-1} + \ ... \ + r_1 \\
  &= \sum_{t=1}^{T}r_t
\end{split}
\end{equation}
Ukamaćivanje logaritamski povrata može se ostvariti zbrajanjem pojedinačnih logaritamskih
povrata. To svojstvo zovemo \emph{aditivnost u vremenu}. Logaritmski povrati također
posjeduju poželjna statistička svojstva \cite{tsay2010}. Za male magnitude vrijedi
$r_t \approx R_t$. Ova aproksimacija je korisna kada se razmatraju kratki vremenski
intervali \cite{anafin02}. Slika \ref{fig:spy-returns} prikazuje dnevne artimetičke
i logaritamske povrate SPDR S\&P 500 ETF. Sa slike vidimo da nema značajne
razlike između artimetičkih i logaritamskih povrata jer su povrati izračunati na kratkom
odnosno dnevnom vremenskom intervalu.

\begin{figure}[htb]
\centering
\includegraphics[width=\textwidth]{img/spy_returns_plot.pdf}
\caption{Artimetički i logaritamski povrati SPDR S\&P 500 ETF-a}
\label{fig:spy-returns}
\end{figure}


\subsubsection{Povrat portfelja}
\label{subsubsec:portfelj}

Artimetički povrat portfelja koji se sastoji od $N$ vrijednosnica je otežana artimetička sredina
\engl{ weighted average} artimetičkih povrata vrijednosnica, gdje je težina \engl{ weight} pojedine
vrijednosnice njezin udio u vrijednosti portfelja \cite{tsay2010}.

Nek je $p$ portfelj kojem je $w_i$ ponder vrijednosnice $i$. Tada je artimetički povrat portfelja $p$ u
trenutku $t$ dan izrazom:
\begin{equation}
  R_{pt} = \sum_{i=1}^{N}w_iR_{it},
\label{eq:portfelj}
\end{equation}
gdje je $R_{it}$ artimetički povrat vrijednosnice $i$ u trenutku $t$. Ovo svojstvo nazivamo \emph{aditivnost
u prostoru vrijednosnica}. Logaritamski povrati ne posjeduju to svojstvo.


\subsubsection{Povrati iznad bezritične kamatne stope}
\label{subsubsec:excess}

Povrati iznad bezrizične kamatne stope \engl{ excess return} predstavlja razliku između ostvarenog
povrata određene imovine i referentnog, bezrizičnog povrata, te mjeri dodatnu kompenzaciju koju
investitor ostvaruje za preuzimanje rizika. Kao referentni povrat najčešće se koriste prinosi
na državne obveznice visoke kreditne kvalitete i kratkog dospijeća, jer se smatra da nose
zanemariv rizik \cite{tsay2010}.

\begin{equation}
  R_t^{excess} = R_t - R_f
\label{eq:excess}
\end{equation}


\section{Statistički modeli povrata}
\label{sec:statisticki}

Prije nego razmotrimo konkretne statističke modele povrata, potrebno je ukratko opisati osnovne
distribucije na kojima će se temeljiti daljnja analiza te načine estimacije njihovih parametara.

\subsubsection{Normalna distribucija}
\label{subsubsec:normal}

Normalna distribucija jedan je od najčešće korištenih probabilističkih modela u statistici i
financijama zbog svoje matematičke jednostavnosti i dobrih teorijskih svojstava.
Ako slučajna varijabla $X$ slijedi normalnu distribuciju sa sredinom $\mu$ i varijancom $\sigma^2$,
tada njezina funkcija gustoće ima oblik \cite{johnson1994vol1}:
\begin{equation}
  f(x) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right).
\end{equation}

Za osmotreni uzorak $\{x_1, x_2, \dots, x_n\}$, procjena sredine dana je aritmetičkom sredinom
\begin{equation}
  \widehat{\mu} = \frac{1}{n}\sum_{i=1}^{n} x_i,
\label{eq:normalna-sredina}
\end{equation}
dok se varijanca procjenjuje izrazom:
\begin{equation}
  \widehat{\sigma^2} = \frac{1}{n}\sum_{i=1}^{n} (x_i - \widehat{\mu})^2.
\label{eq:normalna-varijanca}
\end{equation}


\subsubsection{Lognormalna distribucija}
\label{subsubsec:lognormal}

Lognormalna distribucija koristi se za modeliranje slučajnih varijabli čiji je logaritam
normalno distribuiran. Ako postoji broj $a$ takav da $Y=\ln(X - a)$ prati normalnu
distribuciju, slučajna varijabla $X$ tada slijedi lognormalnu distribuciju. Kako bi to vrijedilo,
vjerojatnost da slučajna varijabla $X$ poprimi vrijednost manju od $a$ mora biti jednaka nuli.
Ako vrijedi $Y \sim \mathcal{N}(\mu, \sigma^2)$, tada $X$ ima gustoću:
\begin{equation}
  f(x) = \frac{1}{(x-a)\sigma\sqrt{2\pi}} \exp\left[-\frac{(\ln(x - a) - \mu)^2}{2\sigma^2}\right]
  , \quad x > a.
\label{eq:lognormalna-gustoca}
\end{equation}

Sredina i varijanca lognormalne distribucije dane su izrazima
\begin{equation}
  E[X] = e^{\mu + \frac{\sigma^2}{2}}, \quad
  \mathrm{Var}[X] = (e^{\sigma^2}-1)e^{2\mu+\sigma^2}.
\end{equation}

Procjena parametara provodi se logaritamskom transformacijom uzorka, nakon čega se primjenjuju
standardne procjene za normalnu distribuciju \cite{johnson1994vol1}.


\subsubsection{Studentova t distribucija}
\label{subsubsec:studentt}

Studentova t distribucija predstavlja generalizaciju normalne distribucije s dodatnim parametrom
broja stupnjeva slobode $\nu$, koji kontrolira debljinu repova. Za manje vrijednosti $\nu$
distribucija ima izraženije repove, čime omogućuje robusnije modeliranje ekstremnih vrijednosti.

Gustoća Studentove t distribucije sa sredinom $\mu$, varijancom $\sigma^2$ i $\nu$ stupnjeva
slobode ima oblik:
\begin{equation}
f(x) = \frac{\Gamma\left(\frac{\nu+1}{2}\right)}{\Gamma\left(\frac{\nu}{2}\right)\sqrt{\nu\pi\sigma^2}}
\left(1 + \frac{(x-\mu)^2}{\nu\sigma^2}\right)^{-\frac{\nu+1}{2}}.
\end{equation}

Za procjenu parametara t distribucije koriste se metode procjene najveće izglednosti \engl{ maximum
likelihood estimation} \cite{johnson1994vol2}.


\subsubsection{Statistička svojstva povrata}

U statističkoj analizi financijskih vremenskih nizova često se polazi od pretpostavke da su aritmetički
povrati nezavisne i jednako distribuirane slučajne varijable s normalnom distribucijom,
konstantnom sredinom i varijancom, čime se značajno pojednostavljuje teorijska obrada i izvođenje
analitičkih rezultata. Međutim, takva pretpostavka suočava se s nizom ograničenja: aritmetički povrati
imaju donju granicu od $-1$, dok normalna distribucija nema ograničenja po realnoj osi,
višeperiodni povrati ne zadržavaju normalnu distribuciju zbog multiplikativne prirode
(\ref{eq:artimeticki-ukamacivanje}), a empirijski podaci često pokazuju odstupanja od normalnosti \cite{cont2001}.

Alternativno možemo pretpostaviti da su logaritamski povrati nezavisno i identično normalno
distribuirani sa sredinom $\mu$ i varijancom $\sigma^2$. S tom pretpostavkom impliciramo da
su aritmetički povrati nezavisno i identično lognormalno distribuirani.
Ovaj pristup ima povoljnija matematička svojstva jer su zbrojevi logaritamskih povrata kroz više
razdoblja također normalno distribuirani (\ref{eq:logaritamski-ukamacivanje}), a pritom se prirodno
zadovoljava donja granica aritmetičkog povrata (\ref{eq:lognormalna-gustoca}). Unatoč tim prednostima,
ni pretpostavka lognormalnosti u potpunosti ne opisuje realna tržišna kretanja, budući da stvarni
financijski povrati često pokazuju deblje repove distribucije i veću učestalost ekstremnih vrijednosti nego
što to predviđa normalna distribucija \cite{tsay2010}.

Kako bismo bolje obuhvatili ta empirijska svojstva, možemo koristiti studentovu $t$-distribuciju.
Slika \ref{fig:spy-returns-pdf} prikazuje distribuciju gustoće vjerojatnosti dnevnih
artimetičkih i logaritamskih povrata SPDR S\&P 500 ETF-a. Također su prikazane distribucije gustoće
vjerojatnosti normalne distribucije i studentove $t$-distribucije s pet stupnjeva slobode
\footnote{Biramo pet stupnjeva slobode kako bi imali konačna prva četiri momenta distribucije.
Za više informacija pogledati \cite{johnson1994vol2}}. Parametri $\mu$ i $\sigma^2$ za normalnu i
$t_5$-distribuciju procjenjeni su iz artimetičkih povrata za lijevi graf i logaritamskih povrata za
desni graf. Sa slike vidimo kako $t_5$-distribucija zbog svojih težih repova vijernije modelira
distribuciju povrata od normalne distribucije.

\begin{figure}[htb]
\centering
\includegraphics[width=\textwidth]{img/spy_pdfs.pdf}
\caption{Distribucija dnevnih artimetičkih i logaritamskih povrata SPY ETF-a}
\label{fig:spy-returns-pdf}
\end{figure}


\subsubsection{Slučajni vektori}
\label{subsubsec:slucajni-vektori}

Nek je $\mathbf{X} = (X_1, \dots, X_p)$ slučajni vektor $p$ slučajnih varijabli.
Tada su vektor sredina i kovarijacijska matrica dani izrazima:
\begin{align}
  E(\mathbf{X}) &= \boldsymbol{\mu}_X = \left[E(X_1), \dots, E(X_p)\right]^\intercal \\
  \mathrm{Cov}(\mathbf{X}) &= \mathbf{\Sigma}_X =
  E\left[\left(\mathbf{X} - \boldsymbol{\mu}_X\right)
  \left(\mathbf{X} - \boldsymbol{\mu}_X\right)^\intercal\right]\text{,}
\end{align}
uz uvijet da dana očekivanj postoje. Neka su $\left\{\mathbf{x_1}, \dots, \mathbf{x_T}\right\}$
realizacije slučajnog vektora $\mathbf{X}$. Tada su uzoračka sredina i kovarijacijska matrica dane
izrazima \cite{tsay2010}:
\begin{equation}
  \widehat{\boldsymbol{\mu}}_x = \frac{1}{T}\sum_{t=1}^{T}\mathbf{x}_t\text{,} \qquad
  \widehat{\mathbf{\Sigma}}_x = \frac{1}{T-1}\sum_{t=1}^{T}\left(\mathbf{x}_t - \widehat{\boldsymbol{\mu}}_x\right)
  \left(\mathbf{x}_t - \widehat{\boldsymbol{\mu}}_x\right)^\intercal\text{.}
\label{eq:multivariatna-sredina-kovarijacijska}
\end{equation}

Ako pretpostavimo da slučajni vektor $\mathbf{X}$ dolazi is multivariatne normalne distribucije s
vektorom sredina $\boldsymbol{\mu}$ i kovarijaciskom matricom $\mathbf{\Sigma}$, tada je funkcija
izglednosti uzorka \engl{ likelihood function} dana jednadžbom \cite{statlect-likelihood}:
\begin{equation}
  \mathcal{L}\left(\boldsymbol{\mu}, \mathbf{\Sigma}; \mathbf{x_1}, \dots, \mathbf{x_T}\right) =
  \left(2\pi\right)^{-\frac{pT}{2}}|\det\left(\mathbf{\Sigma}\right)|^{-\frac{T}{2}}
  \exp\left(-\frac{1}{2}\sum_{t=1}^{T}\left(\mathbf{x}_t - \boldsymbol{\mu}\right)^\intercal
  \mathbf{\Sigma}^{-1}\left(\mathbf{x}_t - \boldsymbol{\mu}\right)\right)\text{.}
\end{equation}
S obzirom da taj oblik funckije izglednosti nije najprikladniji za računanje računalom iskazat ćemo i
njezin logaritamski oblik \engl{ log-likelihood function} te ćemo zamijeniti argument $\mathbf{\Sigma}$
s $\mathbf{\Sigma}^{-1}$:
\begin{equation} \label{eq:log-likelihood}
\begin{split}
  \ln\mathcal{L}&\left(\boldsymbol{\mu}, \mathbf{\Sigma}^{-1}; \mathbf{x_1}, \dots, \mathbf{x_T}\right) =\\
  &= \frac{1}{2}\left(
    -pT\ln(2\pi) + T\ln[\det(\mathbf{\Sigma}^{-1})] - \sum_{t=1}^{T}\left(\mathbf{x}_t - \boldsymbol{\mu}\right)^\intercal
    \mathbf{\Sigma}^{-1}\left(\mathbf{x}_t - \boldsymbol{\mu}\right)
  \right)\text{.}
\end{split}
\end{equation}


\section{Faktorski modeli}
\label{sec:faktorski}

U analizi povrata imovina često se primjenjuju multivarijatne statističke metode
kako bi se proučilo ponašanje i međusobna povezanost većeg broja vrijednosnica unutar portfelja.
Međutim, modeliranje velikog broja vremenskih nizova povrata dovodi do visokodimenzionalnih i
kompleksnih modela koji su složeni za interpretaciju i primjenu u praksi. Empirijska istraživanja
pokazuju da se povrati različitih vrijednosnica često kreću na sličan način, što nas upućuje da
postoje neki zajednički faktori koji utječu na njihovo kretanje. Primjerice, u razdobljima gospodarske
krize pad aktivnosti cijelog gospodarstva obično rezultira istodobnim padom cijena većine vrijednosnica,
dok rast određenog sektora, poput tehnološkog, često dovodi do rasta cijena većine dionica unutar
tog sektora \cite{anafin03}.

Te činjenice omogućuju faktorskim modelima da objasne kretanje većeg broja povrata pomoću
ogarničenog broja zajedničkih faktora te da pojednostavne njihovu analizu. Postoje tri vrste faktorskih
modela \cite{campbell1997}. Prvi su \emph{markoekonomski faktorski modeli} koji se fokusiraju na varijable
kao što su rast BDP-a, kamatne stope, stopa inflacije i slično. U ovakvom su modelu faktori osmotrivi
pa se model može estimirati linearnom regresijom. Drugi su \emph{fundamentalni faktorski modeli} koji
koriste podatke o poduzećima kako bi konsturiali svoje faktore. Treći su \emph{statistički faktorski
modeli} čiji su faktori neosmotrive latentne varijable koje se estimiraju iz podataka \cite{tsay2010}.
Ovaj rad će se fokusirati prvu vrstu odnosno na \emph{makroekonomske faktorske modele}.


\subsection{Linearni faktorski model}
\label{subsec:linearni-faktorski}

Pretpostavimo da imamo $p$ imovina kroz $T$ vremenskih trenutaka. Neka je $r_{it}$ povrat imovine $i$
u trenutku $t$. Opća forma faktorskog modela dana je izrazom:
\begin{equation}
  r_{it} = \alpha_i + \beta_{i1}f_{1t} + \dots + \beta_{im}f_{mt} + \epsilon_{it},
  \quad t=1,\dots,T; \quad i=1,\dots,p,
\label{eq:faktorski-opca}
\end{equation}
gdje je $\alpha_i$ konstanta, $\left\{f_{jt}|j=1,\dots,m\right\}$ su $m$ zajdeničkih (sistemskih)
faktora, $\beta_{ij}$ su koeficijenti imovine $i$ uz faktor $j$, a $\epsilon_{it}$ je specifičan
(idiosinkratski) faktor imovine $i$.

Za faktor $\mathbf{f}_t = \left(f_{1t}, \dots, f_{mt}\right)^\intercal$ vrijedi:
\begin{align}
  E(\mathbf{f}_t) &= \boldsymbol{\mu}_f, \\
  \mathrm{Cov}(\mathbf{f}_t) &= \mathbf{\Sigma}_f, \quad \text{$m \times m$ matrica,}
\end{align}
dok je idiosinkratski faktor $\epsilon_{it}$ modeliran bijelim šumom koji nije koreliran sa
sistemskim faktorima $f_{jt}$ i drugim idiosinkratskim faktorima. Dakle predpostavljamo:
\begin{align}
  \mathrm{E}(\epsilon_{it}) &= 0 \quad \text{za sve } i,t \\
  \mathrm{Cov}(f_{jt}, \epsilon_{is}) &= 0 \quad \text{za sve } i,j,t,s \\
  \mathrm{Cov}(\epsilon_{it}, \epsilon_{js}) &=
  \begin{cases}
    \sigma_i^2, &\text{ako $i = j$ i $t = s$}, \\
    0, &\text{inače.}
  \end{cases}
\end{align}

Jednadžbu (\ref{eq:faktorski-opca}) možemo zapisati i u matričnom obliku za svih $p$ imovina
u trenutku $t$:
\begin{equation}
  \mathbf{r}_t = \boldsymbol{\alpha} + \boldsymbol{\beta}\mathbf{f_t} + \boldsymbol{\epsilon_t},
  \quad t = 1, \dots, T,
\label{eq:faktorski-matricna}
\end{equation}
gdje je $\mathbf{r}_t = \left(r_{1t}, \dots, r_{pt}\right)^\intercal$ vektor povrata,
$\boldsymbol{\alpha} = \left(\alpha_1, \dots, \alpha_p\right)^\intercal$ vektor konstanti,
$\boldsymbol{\beta} = \left[\beta_{ij}\right]$ je $p \times m$ matrica koeficijenata, a
$\boldsymbol{\epsilon}_t = \left(\epsilon_{1t}, \dots, \epsilon_{pt}\right)^\intercal$ je
vektor idiosinkratskih faktora čija je kovarijacijska matrica
$\mathrm{Cov}(\boldsymbol{\epsilon}_t) = \boldsymbol{\Psi} = \mathrm{diag}\left\{
\sigma_1^2, \dots, \sigma_k^2\right\} \; p \times p$ dijagonalna matrica. Očekivanje i kovarijacisku
matricu povrata $\mathbf{r}_t$ možemo računati sljedećim formulama:
\begin{align}
  \mathrm{E}(\mathbf{r}_t) &= \boldsymbol{\alpha} + \boldsymbol{\beta}\boldsymbol{\mu}_f \label{eq:ocekivanje-r} \\
  \mathrm{Cov}(\mathbf{r}_t) &= \boldsymbol{\beta}\boldsymbol{\Sigma}_f\boldsymbol{\beta}^\intercal
  + \boldsymbol{\Psi}. \label{eq:kovarijacijska-r}
\end{align}

Zatim jednadžbu (\ref{eq:faktorski-matricna}) možemo zapisati u sljedećem obliku:
\begin{equation}
  \mathbf{r}_t = \boldsymbol{\xi}\mathbf{g}_t + \boldsymbol{\epsilon}_t,
\end{equation}
gdje $\mathbf{g}_t = \left(1, \mathbf{f}_t^\intercal\right)^\intercal$,
a $\boldsymbol{\xi} = [\boldsymbol{\alpha}, \boldsymbol{\beta}]$ je
$p \times (m+1)$ matrica. Transponiramo li prethodnu jednadžbu i grupiramo podatke za svih $T$ trenutaka
dobivamo:
\begin{equation}
  \mathbf{R} = \mathbf{G}\boldsymbol{\xi}^\intercal + \mathbf{E},
\label{eq:faktorski-matricna-ukupna}
\end{equation}
gdje je $\mathbf{R} \; T \times p$ matrica povrata čiji je $t$-ti redak $\mathbf{r}_t^\intercal$,
$\mathbf{G}$ je $T \times (m+1)$ matrica čiji je $t$-ti redak $\mathbf{g}_t^\intercal$,
$\mathbf{E}$ je $T \times p$ matrica idiosinkratskih faktora čiji je $t$-ti
redak $\boldsymbol{\epsilon}_t^\intercal$ \cite{tsay2010}.

S obzirom da nas zanimaju \emph{makroekonomski faktorski modeli} čiji su faktori $\mathbf{f}_t$
osmotrivi, jednadžba (\ref{eq:faktorski-matricna-ukupna}) ima oblik višestruke multivariatne
linearne regresije. Zbog toga parametre modela možemo estimirati metodom najmanjih kvadrata
\cite{johnson2002}:
\begin{equation}
    \widehat{\boldsymbol{\xi}^\intercal} = \begin{bmatrix}
      \;\widehat{\boldsymbol{\alpha}}^\intercal\; \\
      \;\widehat{\boldsymbol{\beta}}^\intercal\;
    \end{bmatrix} = (\mathbf{G}^\intercal\mathbf{G})^{-1}(\mathbf{G}^\intercal\mathbf{R}),
\label{eq:ols-matrix}
\end{equation}
odakle su $\boldsymbol{\alpha}$ i $\boldsymbol{\beta}$ lako dostupni. Reziduale, odnosno
povrate idiosinkratskih faktora možemo lako dobiti koristeći formulu (\ref{eq:faktorski-matricna-ukupna}):
\begin{equation}
  \widehat{\mathbf{E}} = \mathbf{R} - \mathbf{G}\widehat{\boldsymbol{\xi}}^\intercal.
\label{eq:procjena-reziduala}
\end{equation}

\subsection{Jednofaktorski model povrata}
\label{subsec:jednofaktorski}

Jedan od najpoznatijih \emph{makroekonomskih faktorskih modela} koristi povrat tržišta
kao faktor koji utječe na sve vrijednosnice:
\begin{equation}
  r_{it} = \alpha_i + \beta_ir_{mt} + \epsilon_{it} \qquad i=1, \dots,p; \qquad t=1, \dots, T,
\label{eq:jednofaktorski}
\end{equation}
gdje je $r_{it}$ povrat vrijednosnice $i$ iznad bezrizične kamatne stope, a $r_{mt}$ povrat
tržišta iznad bezrizične kamatne stope. Kod modeliranja dionica, za povrat tržišta $r_{mt}$
uzima se povrat nekog tržišnog indeksa (npr. S\&P 500) iznad bezrizične
kamatne stope. Koeficijenti modela $\alpha_i$ i $\beta_i$ procjenjuju se metodom najmanjih
kvadrata (\ref{eq:ols-matrix}).

Ovaj rad fokusirat će se upravo na jednofaktorski model povrata. Cilj ovog rada biti će
ispitati može li model dubokog učenja, iz prozora povijesnih povrata
$\mathbf{R}_H=\left\{\mathbf{r}_t\right\}_{t=1}^k$,
procijeniti koeficijente $\alpha_i$ i $\beta_i$, koji će bolje odgovarati budućem prozoru povrata
$\mathbf{R}_F=\left\{\mathbf{r}_t\right\}_{t=k+1}^T$,
nego procjena koeficijenata $\alpha_i$ i $\beta_i$ koju možemo dobiti metodom najmanjih kvadrata
na istom povijesnom prozoru povrata $\mathbf{R}_H$ za $1\le k < T$. Način na koji ćemo mjeriti
koliko dobro procjena koeficijenata $\alpha_i$ i $\beta_i$ odgovara budućem prozoru povrata
$\mathbf{R}_F$ biti će detaljnije objašnjen u potpoglavlju \ref{sec:model-dubokog-ucenja}.


\section{Duboko učenje}
\label{sec:duboko-ucenje}

Duboko učenje predstavlja podpodručje strojnog učenja koje se ističe u rješavanju problema s
visokom dimenzionalnošću podataka, kao što su računalni vid, obrada prirodnog jezika,
financijska te slične složene domene. Temeljna ideja dubokog učenja je izgradnja hijerarhijskih,
složenih reprezentacija podataka, koje se dobivaju primjenom uzastopnih nelinearnih transformacija
modeliranih pomoću višeslojnih neuronskih mreža. Osnovni element svake neuronske mreže je umjetni neuron.
Za zadani ulazni vektor $\mathbf{x} = (x_1, \dots, x_n)^\intercal$, izlaz neurona definiramo jednadžbom:
\begin{equation}
  h = f\left(\mathbf{w}^\intercal\mathbf{x} + b\right)
\end{equation}
gdje je $\mathbf{w} = (w_1, \dots, w_n)^\intercal$ vektor težina neurona koji odrežuje doprinos
pojedine komponente ulaznog vektora, a skalar $b$ omogućuje dodatni pomak linearne kombinacije ulaza.
Aktivacijska funkcija $f$ uvodi nelinearnost u model, čime se omogućuje aproskimacija složenih i
nelinearnih odnosa u podatcima \cite{du02}.

Neke od najčešće korištenih aktivacijskih funkcija su sigmoidalna funkcija i hiperbolni tangens,
slika \ref{fig:activations}.
Obje su nelinearne, monotono rastuće i kontinuirano diferencijabilne, što je ključno svojstvo u
procesu učenja neuronskih mreža metodama koje se temelje na gradijentnom spustu. Sigmoidalna funkcija
ima kodomenu u intervalu $\left\langle0,1\right\rangle$, dok hiperbolni tangens poprima vrijednosti u
intervalu $\left\langle-1,1\right\rangle$, pri čemu obje funckije imaju karakterističan S-oblik.

\begin{figure}[htb]
\centering
\includegraphics[width=\textwidth]{img/activation_functions.pdf}
\caption{Primjer aktivacijskih funkcija}
\label{fig:activations}
\end{figure}

Umjetne neurone zatim možemo organizirati u slojeve. Prvi, odnosno ulazni, sloj, zatim proizvoljan broj skrivenih
te na kraju izlazni sloj. Time dobivamo osnovnu arhitekturu neuronske mreže, slika \ref{fig:neural-net}.

\begin{figure}[htb]
\centering
\includegraphics[width=\textwidth]{img/neural-net.pdf}
\caption{Jednostavna neuronska mreža}
\label{fig:neural-net}
\end{figure}

Među najznačajnijim arhitekturama dubokih modela ističu se duboke unaprijende mreže, konvolucijske
neuronske mreže te povratne neuronske mreže. Svaka od navedenih arhitektura prilagođena je specifičnim 
vrstama podataka i problemima. Odabir odgovarajuće arhitekture ovisi o prirodi i strukturi odabranih podataka. 

\subsection{Povratne neuronske mreže}
\label{subsec:povratne-mreze}

Dijeljenje parametara jedna je od ranijih ideja u strojnom učenju i statističkom modeliranju, koja
omogućuje proširivanje modela na primjere različitih oblika te generalizaciju na podatke varijabilne
duljine, osobito u kontekstu sekvencijalnih podataka. Ovakav se princip koristi u skrivenim
Markovljevim modelima, gdje se isti skup parametara, poput matrice prijelaza
$P(\mathbf{s}_t \mid \mathbf{s}_{t-1})$, koristi u svakom vremenskom koraku. Na taj način model ne ovisi
o apsolutnoj poziciji u sekvenci, već isključivo o odnosu između susjednih stanja, što omogućuje
modeliranje sekvenci proizvoljne duljine  i dijeljenje statističke snage kroz različite vremenske korake.
Povratne neuronske mreže \engl{ recurrent neural networks, RNN} preuzimaju i generaliziraju ovu ideju u
okviru dubokog učenja. One su prilagođene za obradu sekvencijalnih podataka tako da u svakom vremenskom
koraku primjenjuju iste težine i istu transformaciju nad ulazom i prethodnim skrivenim stanjem, pri čemu
skriveno stanje $\mathbf{h}_t$ ovisi o trenutnom ulazu $\mathbf{x}_t$ i stanju $\mathbf{h}_{t-1}$
\cite{goodfellow2016}.


\begin{figure}[htb]
\centering
\includegraphics[width=\textwidth]{img/RNN-unrolled.png}
\caption{Jednostavna povratna neuronska mreža \cite{colah2015}}
\label{fig:unrolled-rnn}
\end{figure}

Slika \ref{fig:unrolled-rnn} prikazuje dijagram jednostavne povratne neuronske mreže i njezin razmotani
\engl{ unrolled} oblik kroz vremenske korake. Povratnu neuronsku mrežu moguće je promatrati kao višestruke
kopije iste neuronske mreže, pri čemu svaka kopija prosljeđuje informaciju svojoj sljedbenici u idućem
vremenskom koraku. U razmotanom prikazu jasno se vidi da se u svakom koraku primjenjuje ista RNN ćelija A
s istim parametrima, dok skriveno stanje predstavlja viđeni dio slijeda koja se prenosi kroz vrijeme.
Na taj način model zadržava informaciju o prethodnim ulazima te postupno akumulira kontekst,
što mu omogućuje modeliranje ovisnosti unutar sekvence, neovisno o njezinoj duljini \cite{colah2015}.

Jednostavni povratni model možemo definirati sljedećim jednadžbama:
\begin{align}
  \mathbf{h}_t &= \tanh(\mathbf{W}_{hh}\mathbf{h}_{t-1} + \mathbf{W}_{xh}\mathbf{x}_{t} + \mathbf{b}_h), \\
  \mathbf{o}_t &= \mathbf{W}_{hy}\mathbf{h}_t + \mathbf{b}_o,
\end{align}
gdje matrica $\mathbf{W}_{xh}$ projicira ulaz u prostor reprezentacije stanja, matrica $\mathbf{W}_{hh}$
modelira evoluciju stanja dok matrica $\mathbf{W}_{hy}$ projicira stanje na prostor predikcija. Vektori
$\mathbf{b}_h$ i $\mathbf{b}_o$ omogućuju linearni pomak \cite{du05}.

Međutim, pri učenju dugoročnih zavisnosti u povratnim neuronskim mrežama pojavljuju se značajni
matematički problemi. Gradijenti koji se propagiraju kroz velik broj vremenskih koraka imaju tendenciju
eksponencijalnog smanjivanja (problem nestajućeg gradijenta) ili, rjeđe, eksponencijalnog rasta
(problem eksplodirajućeg gradijenta), što otežava stabilnu optimizaciju modela. Čak i ako pretpostavimo
da su parametri stabilni, utjecaj udaljenih vremenskih koraka postaje eksponencijalno manji u odnosu
na nedavne, zbog čega mreža teško uči dugoročne ovisnosti \cite{goodfellow2016}.


\subsection{LSTM mreže}
\label{subsec:lstm-mreze}

U okviru ovog rada koristit ćemo posebnu vrstu povratnih neuronskih mreža koje nazivamo povratna ćelija s
dugoročnom memorijom \engl{ long short-term memory, LSTM}. LSTM mreže dizajnirane su kako bi
izbjegle probleme nestajućeg i eksplodirajućeg gradijenta te omogućile učenje dugoročnih ovisnosti
u sekvencijalnim podatcima. Zbog toga se često primjenjuju u modeliranju vremenskih nizova \cite{colah2015}.

Razmotana LSTM mreža ima strukturu lančanih ćelija karakterističnu za povratne neuronske mreže, no njene
ponavljajuće ćelije imaju složeniju unutarnju arhitekturu. Umjesto jednog neuronskog sloja, LSTM ćelija
sastoji se od četiri sloja koji imaju specifičnu interakciju.
\begin{figure}[htb]
\centering
\includegraphics[width=\textwidth]{img/LSTM-chain.png}
\caption{Arhitektura LSTM mreže \cite{colah2015}}
\label{fig:lstm-architecture}
\end{figure}
Ključni element LSTM arhitekture jest stanje ćelije $\mathbf{C}_t$, koje predstavlja internu memorijsku
komponentu modela. Ono se propagira kroz vremenske korake koristeći samo linearne transformacije,
čime se omogućuje stabilniji prijenos informacija i ublažava problem nestajućeg gradijenta.
\begin{figure}[htb]
\centering
\includegraphics[width=0.5\textwidth]{img/LSTM-C-line.png}
\caption{Tok stanja ćelije $\mathbf{C}_t$ \cite{colah2015}}
\label{fig:lstm-c-line}
\end{figure}
Za razliku od standardnog skrivenog stanja u jednostavnim RNN mrežama, stanje ćelije eksplicitno
je regulirano posebnim mehanizmom vrata \engl{ gate}. LSTM arhitektura koristi tri vrste vrata: vrata
zaboravljanja, ulazna vrata te izlazna vrata.


\subsubsection{Vrata zaboravljanja}
\label{subsubsec:vrata-zaboravljanja}

Prvi korak u LSTM mreži se odnosi se na određivanje koje informacije iz prethodnog stanja ćelije
$\mathbf{C}_{t-1}$ treba izbaciti. Ta se odluka donosi pomoću vrata zaboravljanja, koja kao ulaz primaju
prethodno skriveno stanje $\mathbf{h}_{t-1}$ i trenutačni ulaz $\mathbf{x}_t$. Rezultat je vektor 
$\mathbf{f}_t$ koji računamo na sljedeći način:
\begin{equation}
  \mathbf{f}_t = \sigma\left(\mathbf{W}_f\cdot\left[\mathbf{h}_{t-1},\mathbf{x}_t\right] + \mathbf{b}_f\right).
\label{eq:forget-gate}
\end{equation}
Pošto vrata zaboravljanja koriste sigmoidu kao aktivacijsku funkciju, $\mathbf{f}_t\in[0,1]^n$.
Elementi stanja $\mathbf{C}_t$ na pozicijama na kojima je vektor $\mathbf{f}_t$ blizu nuli bit
će zaboravljeni, dok će se oni na pozicijama na kojima je vektor $\mathbf{f}_t$ blizu jedinici
propustiti u iduće stanje.

\begin{figure}[htb]
\centering
\includegraphics[width=0.5\textwidth]{img/LSTM-forget-gate.png}
\caption{Vrata zaboravljanja \cite{colah2015}}
\label{fig:lstm-forget-gate}
\end{figure}


\subsubsection{Ulazna vrata}
\label{subsubsec:ulazna-vrata}

U idućem koraku moramo odrediti koju ćemo informaciju iz ulaza $\mathbf{x}_t$ dodati stanju ćelije.
Ovo radimo u dva koraka:
\begin{align}
  \mathbf{i}_t &= \sigma\left(\mathbf{W}_f\cdot\left[\mathbf{h}_{t-1},\mathbf{x}_t\right] + \mathbf{b}_i\right), \\
  \widetilde{\mathbf{C}}_t &= \tanh\left(\mathbf{W}_C\cdot\left[\mathbf{h}_{t-1},\mathbf{x}_t\right] + \mathbf{b}_C\right).
\end{align}
Vektor $\mathbf{i}_t$ određuje koje informacije je potrebno ažurirati, a sloj koji koristi
tangens hiperbolni računa doprinose $\widetilde{\mathbf{C}}_t$ iz ulaza $\mathbf{x}_t$ koje
ćemo dodati stanju ćelije $\mathbf{C}_{t-1}$.

\begin{figure}[htb]
\centering
\includegraphics[width=0.5\textwidth]{img/LSTM-input-gate.png}
\caption{Ulazna vrata \cite{colah2015}}
\label{fig:lstm-input-gate}
\end{figure}


\subsubsection{Ažuriranje stanja ćelije}
\label{subsubsec:azuriranje-celije}

Zatim stanje ćelije zatim ažuriramo na sljedeći način:
\begin{equation}
  \mathbf{C}_t = \mathbf{f}_t \odot \mathbf{C}_{t-1} + \mathbf{i}_t \odot \widetilde{\mathbf{C}}_t.
\end{equation}
gdje je $\odot$ oznaka za Hadamartov umnožak. Množimo staro stanje s $\mathbf{f}_t$ kako bi zaboravili
podatke koje smo odredili ranije. Zatim dodamo umnožak $\mathbf{i}_t \odot \widetilde{\mathbf{C}}_t$
koji predstavlja odabrane doprinose ulaza.

\begin{figure}[htb]
\centering
\includegraphics[width=0.5\textwidth]{img/LSTM-update-state.png}
\caption{Ažuriranje stanja ćelije \cite{colah2015}}
\label{fig:lstm-update-state}
\end{figure}


\subsubsection{Izlazna vrata}
\label{subsubsec:izlazna-vrata}

Na kraju, izlaz ćelije će se temeljiti na novom stanju ćelije $\mathbf{C}_t$. Prvo ćemo pomoću
izlaznih vrata $\mathbf{o}_t$ odrediti koje djelove stanja želimo ćemo zadržati na izlazu.
Potom ćemo stanje ćelije prvo propustit kroz tangens hiperbolni prije nego ga pomnožimo s
izlaznim vratima:
\begin{align}
  \mathbf{o}_t &= \sigma\left(\mathbf{W}_o\cdot\left[\mathbf{h}_{t-1},\mathbf{x}_t\right] + \mathbf{b}_o\right), \\
  \mathbf{h}_t &= \mathbf{o}_t \odot \tanh\left(\mathbf{C}_t\right)
\end{align}

\begin{figure}[htb]
\centering
\includegraphics[width=0.5\textwidth]{img/LSTM-out-gate.png}
\caption{Izlazna vrata \cite{colah2015}}
\label{fig:lstm-out-gate}
\end{figure}


%-------------------------------------------------------------------------------
\chapter{Implementacija}
\label{pog:implementacija}

U ovom poglavlju opisana je programska implementacija predloženog rješenja te alati i biblioteke koje su
omogućile učinkovitu izgradnju, treniranje i evaluaciju modela. Implementacija je realizirana u programskom
jeziku Python 3 zbog njegove široke primjene u području strojnog učenja i bogatog ekosustava znanstvenih
biblioteka. U tablici \ref{tab:biblioteke} su navedene glavne biblioteke korištene u radu, zajedno s
njihovom ulogom u implementaciji.

\begin{table}[h]
\centering
\caption{Korištene Python biblioteke}
\label{tab:biblioteke}
\renewcommand{\arraystretch}{1.5}
\begin{tabular}{lp{10cm}}
\hline
\textbf{Biblioteka} & \textbf{Namjena} \\
\hline
\texttt{hydra-core} & Upravljanje konfiguracijama i pojednostavljenje podešavanja hiperparametara modela \cite{hydra} \\
\texttt{lightning}  & Pojednostavljenje i ubrzavanje procesa treniranja modela \cite{lightning} \\
\texttt{matplotlib} & Vizualizacija podataka i rezultata \cite{matplotlib} \\
\texttt{numpy}      & Rukovanje višedimenzionalnim poljima podataka \cite{numpy} \\
\texttt{pandas}     & Učitavanje i obrada tabličnih podataka \cite{pandas} \\
\texttt{scipy}      & Estimacija parametara distribucija i generiranje sintetičkih podataka \cite{scipy} \\
\texttt{torch}      & Razvoj i treniranje modela strojnog učenja \cite{torch} \\
\hline
\end{tabular}
\end{table}


\section{Podatci}
\label{sec:podatci}

Kao što je najavljeno u potpoglavlju \ref{subsec:jednofaktorski}, model implementiran u ovom radu temelji
se na jednofaktorskom modelu povrata. Budući da se u modelu procjenjuju koeficijenti $\alpha_i$ i $\beta_i$,
na ulazu su potrebni povrati tržišta i dionica iznad bezrizične kamatne stope. Svi korišteni podatci preuzeti
su iz baze podataka dostupne na mrežnim stranicama Kenetha R. Frencha \cite{fammafrench}.


\subsubsection{Tržišni povrati}
\label{subsubsec:trzisni-povrati}

Podatci o dnevnim artimetičkim tržišnim povratima i denvneoj bezrizičnoj kamatnoj stopi preuzeti su iz
skupa podataka \emph{Fama/French 3 Factors [Daily]}.

Tržišni povrat definiran je kao vrijednosno otežani \engl{ value weighted} povrat svih poduzeća iz baze
CRSP inkorporiranih u SAD-u i izlistanih na burzama NYSE, AMEX ili NASDAQ, uz zadovoljenje kriterija
kvalitete podataka. Takva konstrukcija tržišnog portfelja po svojoj strukturi i obuhvatu vrlo je slična
indeksu koji prati SPDR S\&P 500 ETF, budući da oba predstavljaju široko diverzificirani presjek
američkog tržišta kapitala.

Bezrizična kamatna stopa definirana je kao prinos na jednomjesečni američki trezorski zapis. Do svibnja
2024. godine podatci potječu od Ibbotson Associates, dok se od lipnja 2024. godine koristi referentna stopa
iz ICE BofA US 1-Month Treasury Bill Indexa.


\subsubsection{Povrati dionica}
\label{subsubsec:povrati-dionica}

Podatci o dnevnim artimetičkim povratima dionica preuzeti su iz skupa \emph{25 Portfolios Formed on Size and
Book-to-Market (5 $\times$ 5) [Daily]}. Riječ je o 25 portfelja formiranih kao presjek pet portfelja
prema veličini poduzeća \engl{market equity, ME} i pet portfelja prema omjeru knjigovodstvene i tržišne
vrijednosti kapitala \engl{ book-to-market equity, BE/ME}. Portfelji se konstruiraju na kraju lipnja
svake godine kao presjeci:
\begin{itemize}
  \item pet kvintila prema tržišnoj kapitalizaciji ME
  \item pet kvintila prema omjeru BE/ME
\end{itemize}

U ovom radu koriste se povrati portfelja, a ne pojedinačnih dionica. Razlog tome je što pojedinačne dionice
tijekom vremena ulaze i izlaze s tržišta, što može uzrokovati probleme u konstrukciji uravnoteženih
vremenskih nizova.


\section{Obrada podataka}
\label{sec:obrada-podataka}

U ovom potpoglavlju ćemo opisati kako od podataka navedenih u potpoglavlju \ref{sec:podatci} konstruirati
značajke za naš model. Prvo nakon što smo učitali podatke o artimetičkim povratima tržišta, portfelja i
bezrizičnu kamatnu stopu, uklanjamo nedostajuće podatke. U našim podatcima to su retci u kojima se nalaze
vrijednosi -99.99 ili -999. Podatke zatim filtriramo na raspon od 1. 1. 1950. do 28. 11. 2025. uključivo.
Odbacujemo podatke prije 1950. godine jer je presjek prvog kvintila po tržišnoj kapitalizaciji i prvog
kvintila po omjeru BE/ME bio jako nestabilan\footnote{U tim periodima se taj presjek sastojao od svega
nekoliko dionica}.

Sljedeći korak je od povrata tržišta i portfelja oduzeti bezrizičnu kamatnu stopu kako bi dobili povrate iznad 
bezrizične kamatne stope. Neka je $R_{Mt}$ dnevni artimetički povrata iznad bezrizične kamatne stope tržišta u
trenutku $t$, a $R_{it}$ dnevni artimetički povrata iznad bezrizične kamatne stope portfelja $i$ u trenutku
$t$. Definirajmo zatim vektore $\mathbf{R}_M = \left(R_{M1}, \dots R_{MT}\right)^\intercal$ i
$\mathbf{R}_i = \left(R_{i1}, \dots, R_{iT}\right)^\intercal$ te matricu
$\mathbf{R}_{P25} = [\mathbf{R}_1, \dots, \mathbf{R}_{25}]$ oblika $T \times 25$, gdje je $T$ ukupan broj
dnevnih povrata u našim podatcima.

U idućem koraku vektor $\mathbf{R}_M$ i matricu $\mathbf{R}_{P25}$ potrebno je uzorkovati kliznim prozorom
duljine 90 i korakom 30:
\begin{align}
  \mathbf{w}_{Mk} &= (R_{Mi}, \dots, R_{M(i+89)})^\intercal &i=30k+1; \quad 0 \le k \le \left\lfloor\frac{T-90}{30}\right\rfloor, k \in \mathbb{Z}  \\
  \mathbf{W}_{Pk} &= \begin{bmatrix}
      \; \mathbf{R}_{P25}^{(i)} \; \\
      \; \vdots \; \\
      \; \mathbf{R}_{P25}^{(i+89)} \;
    \end{bmatrix} &i=30k+1; \quad 0 \le k \le \left\lfloor\frac{T-90}{30}\right\rfloor, k \in \mathbb{Z}
\end{align}
gdje je $\mathbf{R}_{P25}^{(i)}$ $i$-ti redak matrice $\mathbf{R}_{P25}$. Dobivene prozore zatim dijelimo na
način da prvih 60 povrata prozora uzimamo kao povijesne povrate,a posljednjih 30 povrata kao buduće:
\begin{align}
  \mathbf{x}_{Mk} &= (w_{Mk1}, \dots, w_{Mk60})^\intercal & \mathbf{y}_{Mk} &= (w_{Mk61}, \dots, w_{Mk90})^\intercal, \\
  \mathbf{X}_{Pk} &= \begin{bmatrix}
      \; \mathbf{W}_{Pk}^{(1)} \; \\
      \; \vdots \; \\
      \; \mathbf{W}_{Pk}^{(60)} \;
    \end{bmatrix} & \mathbf{Y}_{Pk} &= \begin{bmatrix}
      \; \mathbf{W}_{Pk}^{(61)} \; \\
      \; \vdots \; \\
      \; \mathbf{W}_{Pk}^{(90)} \;
    \end{bmatrix},
\end{align}
gdje $w_{Mki}$ $i$-ti element vektora $\mathbf{w}_{Mk}$. Primjeti da se podatci, zbog preklapanja prozora, iz
$\mathbf{R}_M$ i $\mathbf{R}_{P25}$ ponavljaju u uzorkovanim podatcima. To preklapanje je nužno kako bi imali
dovoljno uzorka za model. Korak kliznog prozora jednak je veličini budućih prozora kako se barem oni nebi
preklapali.

Prije nego što povijesni prozori $\mathbf{x}_{Mk}$ i $\mathbf{X}_{Pk}$ budu spremni za naš model, dodajemo još
jednu značajku u obliku interakcije:
\begin{align}
  \mathbf{X}_{Mk} &= \mathbf{x}_{Mk} \cdot \mathbf{1}_{25}^\intercal, \\
  \mathbf{X}_{PMk} &= \mathbf{X}_{Mk} \odot \mathbf{X}_{Pk},
\end{align}
gdje je $\mathbf{1}_n$ vektor jedinica dužine $n$. Neka je
$\mathbf{X}_k = [\mathbf{X}_{Pk}^\intercal, \mathbf{X}_{Mk}^\intercal, \mathbf{X}_{PMk}^\intercal]$ tenzor
oblika $25\times60\times3$. Time smo konstruirali ulazni tenzor za naš model.


Jedna od funkcija cilja našeg modela je negativna logaritamska izglednost. Za njezin izračun potrebno nam je
očekivanje i kovarijacijska matrica povrata (\ref{eq:log-likelihood}). S obzirom da naš model pretpostavlja
jednofaktorski model povrata (\ref{eq:jednofaktorski}) očekivanje i kovarijacijsku matricu možemo izračunati
koristeći formule (\ref{eq:ocekivanje-r}) i (\ref{eq:kovarijacijska-r}). Naš model procjenjuje koeficijente
$\widehat{\boldsymbol{\alpha}}$ i $\widehat{\boldsymbol{\beta}}$, stoga kako bi mogli računati negativnu log
izglednost moramo još procijeniti $\mu_f$, $\sigma_f^2$ i $\boldsymbol{\Psi}$ iz prozora budućih povrata. S
obzirom da je naš faktor predstavljaju povrati tržišta, $\mu_{fk}$ i $\sigma_{fk}^2$ procjenjujemo iz prozora
budućih povrat tržišta $\mathbf{y}_{Mk}$ pomoću izraza (\ref{eq:normalna-sredina}) i
(\ref{eq:normalna-varijanca}). Kako bi izračunali procjenu kovarijacijske matrice reziduala
$\widehat{\boldsymbol{\Psi}}$ primjenjujemo formulu (\ref{eq:multivariatna-sredina-kovarijacijska}) na
rezidualima $\widehat{\mathbf{E}}$. Kako bi izračunali $\widehat{\mathbf{E}}$ možemo iskoristiti formulu
(\ref{eq:procjena-reziduala}). Za nju su nam potrebni parametri $\widehat{\boldsymbol{\xi}}^\intercal$ koje
možemo dobiti primjenom metode najmanjih kvadrata (\ref{eq:ols-matrix}) na $\mathbf{y}_{Mk}$ i
$\mathbf{Y}_{Pk}$. Time smo dobili procjene za $\widehat{\boldsymbol{\Psi}}_k$. Skup
$\left\{\mathbf{Y}_{Pk}, \mathbf{y}_{Mk}, \mu_{fk}, \sigma_{fk}^2, \widehat{\boldsymbol{\Psi}}_k\right\}$
predstavlja ciljne varijable naših $k$ uzorka.


\section{Sintetički podatci}
\label{sec:sinteticki}

Osim stvarnih podataka naš model trenirali smo i na sintetičkim podatcima. Prednost sintetičkih podataka
je to što ih možemo generirti prozivljno mnogo te znamo stvarne vrijendosti parametara koje pokušavamo
procijeniti. Kako bi sintetički podatci mogli pomoći modelu u generalizaciji na stvarne podatke moraju biti
što sličniji stvarnim podatcima.

Za simulaciju tržišnih povrata odabralismo studentovu $t$-distribuciju s pet stupnjeva slobode. Za procjenu
$\mu_M$ i $\sigma_M^2$ koristili smo procjenu najveće izglednosti koju nudi biblioteka \texttt{scipy} na
podatcima $\mathbf{R}_M$. Primjenjivanjem metode najmanjih kvadrata (\ref{eq:ols-matrix}) na
$\mathbf{W}_{Mk}$ i $\mathbf{W}_{Pk}$ dobivamo $k$ parametara $\widehat{\boldsymbol{\xi}}_k$.
To nam omogućuje da uz formulu (\ref{eq:procjena-reziduala}) dobijemo $k$ reziduala $\widehat{\mathbf{E}}_k$.
Iz parametra $\widehat{\boldsymbol{\xi}}_k$ su lako dostupni $\widehat{\boldsymbol{\alpha}}_k$ i
$\widehat{\boldsymbol{\beta}}_k$. Potom sve elemente $\widehat{\mathbf{E}}_k$,
$\widehat{\boldsymbol{\alpha}}_k$ i $\widehat{\boldsymbol{\beta}}_k$ promatramo kao realizacije triju
normalnih distribucija $\{\epsilon_i\}_{i=1}^{90\times25\times k}$, $\{\alpha_i\}_{i=1}^{25\times k}$ i
$\{\beta_i\}_{i=1}^{25\times k}$. Primjenom formula (\ref{eq:normalna-sredina}) i
(\ref{eq:normalna-varijanca}) dobivamo procjene $\widehat{\mu}_{\epsilon}$, $\widehat{\sigma}_{\epsilon}^2$,
$\widehat{\mu}_{\alpha}$, $\widehat{\sigma}_{\alpha}^2$, $\widehat{\mu}_{\beta}$ i $\widehat{\sigma}_{\beta}^2$.

TODO Generiranje podataka iz dristribucija

\section{Model dubokog učenja}
\label{sec:model-dubokog-ucenja}

TODO Objasniti arhitekturu našeg modela i različite funkcije cilja

%-------------------------------------------------------------------------------
\chapter{Rezultati}
\label{pog:rezultati}

TODO Rezultati i rasprava


%--- ZAKLJUČAK / CONCLUSION ----------------------------------------------------
\chapter{Zaključak}
\label{pog:zakljucak}

TODO Zaključak


%--- LITERATURA / REFERENCES ---------------------------------------------------

% Literatura se automatski generira iz zadane .bib datoteke / References are automatically generated from the supplied .bib file
% Upiši ime BibTeX datoteke bez .bib nastavka / Enter the name of the BibTeX file without .bib extension
\bibliography{literatura}



%--- SAŽETAK / ABSTRACT --------------------------------------------------------

% Sažetak na hrvatskom
\begin{sazetak}
  Unesite sažetak na hrvatskom.

\end{sazetak}

\begin{kljucnerijeci}
  prva ključna riječ; druga ključna riječ; treća ključna riječ
\end{kljucnerijeci}


% Abstract in English
\begin{abstract}
  Enter the abstract in English.

\end{abstract}

\begin{keywords}
  the first keyword; the second keyword; the third keyword
\end{keywords}


\end{document}
